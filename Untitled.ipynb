{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cbbbb94-e020-478c-960d-b095b9c42e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "# load datset concerning ratings\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv (r\"C:\\Users\\msi\\PycharmProjects\\Data science projects\\Recommendation system\\ml-latest-small\\ratings.csv\")\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10157637-df19-4574-87c9-58f116c69747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a user matrix item to represent the interactions between user and movies\n",
    "\n",
    "user_item_matrix = data.pivot (index= \"userId\", columns = \"movieId\", values= \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac11899f-3d8f-4775-a232-f458a768cab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\users\\msi\\anaconda3\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.13.1)\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8730  0.8718  0.8696  0.8770  0.8767  0.8736  0.0029  \n",
      "MAE (testset)     0.6701  0.6721  0.6662  0.6762  0.6720  0.6713  0.0032  \n",
      "Fit time          1.41    1.37    1.31    1.31    1.33    1.35    0.04    \n",
      "Test time         0.17    0.22    0.15    0.21    0.16    0.18    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87297811, 0.87179828, 0.86962176, 0.87704459, 0.87672646]),\n",
       " 'test_mae': array([0.67014739, 0.67209561, 0.66618817, 0.67621544, 0.67198355]),\n",
       " 'fit_time': (1.4146902561187744,\n",
       "  1.3716683387756348,\n",
       "  1.3086533546447754,\n",
       "  1.3092830181121826,\n",
       "  1.3294732570648193),\n",
       " 'test_time': (0.16770696640014648,\n",
       "  0.22151803970336914,\n",
       "  0.14880752563476562,\n",
       "  0.21367359161376953,\n",
       "  0.15500664710998535)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collaborative filtering based on similarity\n",
    "#calculating similarities between users and items (cosine similarity)\n",
    "#use of surprise library for a simple model\n",
    "\n",
    "!pip install scikit-surprise\n",
    "\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, cv=5, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f238684-d9e5-4286-9a4c-44926122cb9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m algo \u001b[38;5;241m=\u001b[39m SVD()\n\u001b[0;32m      5\u001b[0m algo\u001b[38;5;241m.\u001b[39mfit(data\u001b[38;5;241m.\u001b[39mbuild_full_trainset())\n\u001b[1;32m----> 7\u001b[0m user_id \u001b[38;5;241m=\u001b[39m ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]  \n\u001b[0;32m      8\u001b[0m item_id \u001b[38;5;241m=\u001b[39m ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mpredict(user_id, item_id)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "#make some predictions\n",
    "#predict a note for a user and a given item\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(data.build_full_trainset())\n",
    "\n",
    "user_id = ratings['userId'].iloc[0]  \n",
    "item_id = ratings['movieId'].iloc[0]\n",
    "\n",
    "prediction = algo.predict(user_id, item_id)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903500e-f2f0-4898-a8a1-9848cf6a3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data visualisation\n",
    "# ratings distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Distribution des notes\n",
    "sns.histplot(ratings['rating'], bins=10, kde=False, color='blue')\n",
    "plt.title(\"Ratings distrbution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Number of ratings\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c111a-86bb-4079-ad1a-6d1646d18d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 movies\n",
    "\n",
    "# Counting number of ratings per movie\n",
    "top_movies = ratings.groupby('movieId')['rating'].count().nlargest(10)\n",
    "\n",
    "# Join with movie titles\n",
    "top_movies = pd.merge(top_movies, movies, on='movieId', how='left')\n",
    "\n",
    "# Visualise\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_movies['rating'], y=top_movies['title'], palette=\"viridis\")\n",
    "plt.title(\"Top 10 most rated\")\n",
    "plt.xlabel(\"Number of ratings\")\n",
    "plt.ylabel(\"Movie title\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0a84c-e6c0-4563-96ed-3c3d70fba6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the model's performances\n",
    "#RMSE (Root Mean Square Error) to measure the mean deviation between predictions and real evaluations\n",
    "\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse\n",
    "\n",
    "# load data with Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# divide data in train/test\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# train an SVD model\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# make predictions on test data\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calculate RMSE\n",
    "print(\"RMSE :\", rmse(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0cd8b-039e-419e-b2a8-a990766c1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE (Mean Absolute Error) measures the mean absolute difference between predictions and real scores\n",
    "\n",
    "from surprise.accuracy import mae\n",
    "\n",
    "# Calculer le MAE\n",
    "print(\"MAE :\", mae(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077fc24-7334-421d-a1fe-2416bceeb55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the predictions\n",
    "# histogramme of deviations to explore how close the predictions are to the real scores\n",
    "\n",
    "# Calculate the deviations\n",
    "errors = [pred.est - pred.r_ui for pred in predictions]\n",
    "\n",
    "# Visualise\n",
    "sns.histplot(errors, bins=20, kde=True, color='red')\n",
    "plt.title(\"Distribution of Error prediction\")\n",
    "plt.xlabel(\"Error (Prediction - Real rating)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50637c0b-7f90-4b4f-b4fd-fb159af70d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the  generated recommendations\n",
    "# the  movies suggested to a given user\n",
    "\n",
    "# get a list of all movies the user didn't rate\n",
    "user_id = 1\n",
    "all_movie_ids = set(movies['movieId'])\n",
    "rated_movie_ids = set(ratings[ratings['userId'] == user_id]['movieId'])\n",
    "unrated_movie_ids = list(all_movie_ids - rated_movie_ids)\n",
    "\n",
    "# forecast the ratings for these movies\n",
    "recommendations = []\n",
    "for movie_id in unrated_movie_ids:\n",
    "    pred = algo.predict(user_id, movie_id)\n",
    "    recommendations.append((movie_id, pred.est))\n",
    "\n",
    "# class by predicted rating\n",
    "recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Add movie titles\n",
    "recommended_movies = pd.DataFrame(recommendations, columns=['movieId', 'PredictedRating'])\n",
    "recommended_movies = pd.merge(recommended_movies, movies, on='movieId', how='left')\n",
    "\n",
    "# Display the recommendations\n",
    "print(recommended_movies[['title', 'PredictedRating']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d6c93-a47c-4575-bf52-73599eedd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the model's performance on different users group\n",
    "\n",
    "# RMSE to see if some users are more predictable than others\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#group predictions by user\n",
    "\n",
    "user_errors = defaultdict(list)\n",
    "for pred in predictions:\n",
    "    user_errors[pred.uid].append(abs(pred.est - pred.r_ui))\n",
    "\n",
    "# Calculate the mean errors per user\n",
    "user_rmse = {uid: sum(errors) / len(errors) for uid, errors in user_errors.items()}\n",
    "\n",
    "# Visualise\n",
    "sns.histplot(list(user_rmse.values()), bins=20, kde=True, color='green')\n",
    "plt.title(\"RMSE distribution per user\")\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
